{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlejandroHerrera15/Caso_estudio_salud/blob/main/g_Modelos_complemento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El tunning se realizo en colab ya que visual estaba presentando problemas con el directorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCdcVkklwDLf",
        "outputId": "3f315e85-e42a-4f08-a50a-0e0e7270ace9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lectura de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTA: Los dos primeros tunning estan realizados con una dimension de las imagenes de 120x120 pixeles en tres canales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "A4ZHyIYvvye2",
        "outputId": "99d72ef6-8ce8-4a00-b5d1-e5d8168330e0"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'x_train.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4730524c02af>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m### cargar bases_procesadas ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x_train.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_train.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x_test.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'x_train.pkl'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import joblib ### para cargar array\n",
        "########Paquetes para NN #########\n",
        "import tensorflow as tf\n",
        "from sklearn import metrics ### para analizar modelo\n",
        "import pandas as pd\n",
        "####instalar paquete !pip install keras-tuner\n",
        "import keras_tuner as kt\n",
        "\n",
        "### cargar bases_procesadas ####\n",
        "\n",
        "x_train = joblib.load('x_train.pkl')\n",
        "y_train = joblib.load('y_train.pkl')\n",
        "x_test = joblib.load('x_test.pkl')\n",
        "y_test = joblib.load('y_test.pkl')\n",
        "\n",
        "x_train[0]\n",
        "x_train=x_train.astype(\"float32\")\n",
        "x_test=x_test.astype(\"float32\")\n",
        "x_train.max()\n",
        "x_train.min()\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "\n",
        "x_train.shape\n",
        "x_test.shape\n",
        "\n",
        "np.product(x_train[15].shape) ## cantidad de variables por imagen\n",
        "\n",
        "np.unique(y_train, return_counts=True)\n",
        "np.unique(y_test, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "2TYGlZBh5UeV",
        "outputId": "d9fe023b-e196-4a67-8ce7-6214463fe36b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4070, 120, 120, 3)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(694, 120, 120, 3)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "43200"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(x_train.shape)\n",
        "display(x_test.shape)\n",
        "display(np.product(x_train[15].shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modelo con tunning 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26-WI-Tx-5U-",
        "outputId": "6ec68f65-b35e-4356-f7f9-befe34ce0f5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 07m 26s]\n",
            "precision: 0.7274826765060425\n",
            "\n",
            "Best precision So Far: 0.9397445917129517\n",
            "Total elapsed time: 01h 04m 52s\n",
            "Results summary\n",
            "Results in my_dir/helloworld\n",
            "Showing 10 best trials\n",
            "Objective(name=\"precision\", direction=\"max\")\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "DO: 0.30000000000000004\n",
            "rs: 0.004\n",
            "optimizer: adam\n",
            "Score: 0.9397445917129517\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "DO: 0.4\n",
            "rs: 0.002\n",
            "optimizer: rmsprop\n",
            "Score: 0.933386504650116\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "DO: 0.30000000000000004\n",
            "rs: 0.002\n",
            "optimizer: rmsprop\n",
            "Score: 0.9190267324447632\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "DO: 0.2\n",
            "rs: 0.004\n",
            "optimizer: rmsprop\n",
            "Score: 0.9186413884162903\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "DO: 0.45000000000000007\n",
            "rs: 0.001\n",
            "optimizer: rmsprop\n",
            "Score: 0.894385576248169\n",
            "\n",
            "Trial 07 summary\n",
            "Hyperparameters:\n",
            "DO: 0.15000000000000002\n",
            "rs: 0.001\n",
            "optimizer: sgd\n",
            "Score: 0.7908182144165039\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "DO: 0.4\n",
            "rs: 0.004\n",
            "optimizer: sgd\n",
            "Score: 0.7414555549621582\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "DO: 0.45000000000000007\n",
            "rs: 0.001\n",
            "optimizer: adam\n",
            "Score: 0.7377763986587524\n",
            "\n",
            "Trial 05 summary\n",
            "Hyperparameters:\n",
            "DO: 0.45000000000000007\n",
            "rs: 0.004\n",
            "optimizer: sgd\n",
            "Score: 0.7369884848594666\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "DO: 0.4\n",
            "rs: 0.005\n",
            "optimizer: sgd\n",
            "Score: 0.7274826765060425\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 16)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 74, 74, 16)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 36, 36, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 41472)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                2654272   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2659425 (10.14 MB)\n",
            "Trainable params: 2659425 (10.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "##### función con definicion de hiperparámetros a afinar\n",
        "hp = kt.HyperParameters()\n",
        "def build_model(hp):\n",
        "\n",
        "    dropout_rate=hp.Float('DO', min_value=0.1, max_value= 0.5, step=0.05)\n",
        "    reg_strength = hp.Float(\"rs\", min_value=0.001, max_value=0.005, step=0.001)\n",
        "    optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop']) ### en el contexto no se debería afinar\n",
        "\n",
        "    #filtros1 = hp.Int(\"filtros1\", min_value=16, max_value=128, step=32)\n",
        "    #filtros2 = hp.Int(\"filtros2\", min_value=32, max_value=128, step=32)\n",
        "    #filtros3 = hp.Int(\"filtros3\", min_value=64, max_value=128, step=32)\n",
        "\n",
        "    ####hp.Int\n",
        "    ####hp.Choice\n",
        "\n",
        "\n",
        "    model= tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:], kernel_regularizer=tf.keras.regularizers.l2(reg_strength)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg_strength)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg_strength)),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    elif optimizer == 'sgd':\n",
        "        opt = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "    else:\n",
        "        opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=opt, loss=\"binary_crossentropy\",  metrics=[\"Precision\"],\n",
        "    )\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "###########\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    hyperparameters=hp,\n",
        "    tune_new_entries=True,\n",
        "    objective=kt.Objective(\"precision\", direction=\"max\"),\n",
        "    max_trials=10,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"helloworld\",\n",
        ")\n",
        "\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test), batch_size=100)\n",
        "\n",
        "fc_best_model = tuner.get_best_models(num_models=1)[0]\n",
        "tuner.results_summary()\n",
        "fc_best_model.summary()\n",
        "\n",
        "\n",
        "#################### Mejor redes ##############\n",
        "#fc_best_model.save('salidas\\\\fc_model.h5')\n",
        "#cnn_model.save('salidas\\\\cnn_model.h5')\n",
        "\n",
        "\n",
        "#cargar_modelo=tf.keras.models.load_model('salidas\\\\cnn_model.h5')\n",
        "#cargar_modelo.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardardo de modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jCPnuOpmb8U",
        "outputId": "28086745-f35a-44f9-9dd1-8f8bc9e1135f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "fc_best_model.save('/content/salidas/fc_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modelo con tunning 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut6Wgc5vAzSU",
        "outputId": "8f99c973-fc4a-49e8-dae6-dee884a2a9c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 06m 26s]\n",
            "precision: 0.6182500720024109\n",
            "\n",
            "Best precision So Far: 0.9268389940261841\n",
            "Total elapsed time: 01h 05m 23s\n",
            "Results summary\n",
            "Results in my_dir/helloworld\n",
            "Showing 10 best trials\n",
            "Objective(name=\"precision\", direction=\"max\")\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "DO: 0.4\n",
            "rs: 0.005\n",
            "optimizer: adam\n",
            "activation: relu\n",
            "learning_rate: 0.0001\n",
            "Score: 0.9268389940261841\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "DO: 0.30000000000000004\n",
            "rs: 0.004\n",
            "optimizer: adam\n",
            "activation: relu\n",
            "learning_rate: 0.0001\n",
            "Score: 0.9267516136169434\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "DO: 0.45000000000000007\n",
            "rs: 0.003\n",
            "optimizer: rmsprop\n",
            "activation: tanh\n",
            "learning_rate: 0.0001\n",
            "Score: 0.890782356262207\n",
            "\n",
            "Trial 07 summary\n",
            "Hyperparameters:\n",
            "DO: 0.5\n",
            "rs: 0.001\n",
            "optimizer: sgd\n",
            "activation: tanh\n",
            "learning_rate: 0.01\n",
            "Score: 0.8858984112739563\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "DO: 0.35\n",
            "rs: 0.001\n",
            "optimizer: sgd\n",
            "activation: leaky_relu\n",
            "learning_rate: 0.01\n",
            "Score: 0.8682724833488464\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "DO: 0.2\n",
            "rs: 0.004\n",
            "optimizer: sgd\n",
            "activation: relu\n",
            "learning_rate: 0.01\n",
            "Score: 0.8661944270133972\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "DO: 0.25\n",
            "rs: 0.005\n",
            "optimizer: sgd\n",
            "activation: relu\n",
            "learning_rate: 0.0001\n",
            "Score: 0.6317090392112732\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "DO: 0.1\n",
            "rs: 0.004\n",
            "optimizer: rmsprop\n",
            "activation: tanh\n",
            "learning_rate: 0.01\n",
            "Score: 0.6182500720024109\n",
            "\n",
            "Trial 05 summary\n",
            "Hyperparameters:\n",
            "DO: 0.45000000000000007\n",
            "rs: 0.004\n",
            "optimizer: rmsprop\n",
            "activation: tanh\n",
            "learning_rate: 0.01\n",
            "Score: 0.613457202911377\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "DO: 0.25\n",
            "rs: 0.004\n",
            "optimizer: adam\n",
            "activation: relu\n",
            "learning_rate: 0.1\n",
            "Score: 0.6086832284927368\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 16)        0         \n",
            " D)                                                              \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " dropout (Dropout)           (None, 74, 74, 16)        0         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 32)        0         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " g2D)                                                            \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " dropout_1 (Dropout)         (None, 36, 36, 32)        0         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " flatten (Flatten)           (None, 41472)             0         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " dense (Dense)               (None, 64)                2654272   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " dropout_2 (Dropout)         (None, 64)                0         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2659425 (10.14 MB)\n",
            "Trainable params: 2659425 (10.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#### función con definicion de hiperparámetros a afinar\n",
        "hp = kt.HyperParameters()\n",
        "def build_model(hp):\n",
        "\n",
        "    dropout_rate=hp.Float('DO', min_value=0.1, max_value= 0.5, step=0.05)\n",
        "    reg_strength = hp.Float(\"rs\", min_value=0.001, max_value=0.005, step=0.001)\n",
        "    optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop']) ### en el contexto no se debería afinar\n",
        "    activation_opt = hp.Choice('activation', ['tanh', 'leaky_relu', 'relu'])  # la función de activación\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01, 0.001, 0.0001])\n",
        "\n",
        "    #filtros1 = hp.Int(\"filtros1\", min_value=16, max_value=128, step=32)\n",
        "    #filtros2 = hp.Int(\"filtros2\", min_value=32, max_value=128, step=32)\n",
        "    #filtros3 = hp.Int(\"filtros3\", min_value=64, max_value=128, step=32)\n",
        "\n",
        "    ####hp.Int\n",
        "    ####hp.Choice\n",
        "\n",
        "\n",
        "    model= tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, kernel_size=(3, 3), activation=activation_opt, input_shape=x_train.shape[1:], kernel_regularizer=tf.keras.regularizers.l2(reg_strength)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=activation_opt, kernel_regularizer=tf.keras.regularizers.l2(reg_strength)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation=activation_opt, kernel_regularizer=tf.keras.regularizers.l2(reg_strength)),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        opt = tf.keras.optimizers.SGD(learning_rate=hp_learning_rate)\n",
        "    else:\n",
        "        opt = tf.keras.optimizers.RMSprop(learning_rate=hp_learning_rate)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=opt, loss=\"binary_crossentropy\",  metrics=[\"Precision\"],\n",
        "    )\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "###########\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    hyperparameters=hp,\n",
        "    tune_new_entries=True,\n",
        "    objective=kt.Objective(\"precision\", direction=\"max\"),\n",
        "    max_trials=10,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"helloworld\",\n",
        ")\n",
        "\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test), batch_size=100)\n",
        "\n",
        "fc_best_model = tuner.get_best_models(num_models=1)[0]\n",
        "tuner.results_summary()\n",
        "fc_best_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardado de modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AECmC7qwg1ml"
      },
      "outputs": [],
      "source": [
        "\n",
        "#################### Mejor redes ##############\n",
        "fc_best_model.save('/content/salidas/fc_model+.h5')\n",
        "#cnn_model.save('salidas\\\\cnn_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para este modelo se balancearon las clases con la funcion SMOTEENN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBA9Gg0O4cDW",
        "outputId": "f1efce1a-db31-4e58-eb43-02acfd9f0025"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2870, 150, 150, 3)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTheTmC46MxT",
        "outputId": "caeecdaf-5947-4a7c-8fe6-1b6a5fb80859"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0, 1], dtype=int32), array([ 395, 2475]))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(y_train,return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53al0i2zvufp"
      },
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTEENN\n",
        "smote_enn = SMOTEENN(random_state=42)\n",
        "x_train_res=x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]*x_train.shape[3])\n",
        "X_train_resampled, y_train_resampled = smote_enn.fit_resample(x_train_res, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-0-jClp5n3j",
        "outputId": "4dca98e9-a2d0-415e-9653-b14e46d37a59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4362, 67500)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_resampled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6LHRh5Z5rEX",
        "outputId": "65553ae6-6e6a-45d5-9231-7d01975313aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0, 1], dtype=int32), array([2384, 2097]))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(y_train_resampled,return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2LyOeAw75qK"
      },
      "outputs": [],
      "source": [
        "x_train_r = X_train_resampled.reshape((X_train_resampled.shape[0], x_train.shape[1], x_train.shape[2], x_train.shape[3]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Modelo con tunning 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3V7BAXWvvEe",
        "outputId": "ae2716fc-7149-4fe2-e546-669ea08bd5e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 05m 25s]\n",
            "precision: 0.9043062329292297\n",
            "\n",
            "Best precision So Far: 0.9781990647315979\n",
            "Total elapsed time: 00h 44m 15s\n",
            "Results summary\n",
            "Results in my_dir/tunnig2\n",
            "Showing 10 best trials\n",
            "Objective(name=\"precision\", direction=\"max\")\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "DO: 0.1\n",
            "rs: 0.003\n",
            "optimizer: adam\n",
            "activation: leaky_relu\n",
            "learning_rate: 0.001\n",
            "Score: 0.9781990647315979\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "DO: 0.25\n",
            "rs: 0.002\n",
            "optimizer: rmsprop\n",
            "activation: leaky_relu\n",
            "learning_rate: 0.001\n",
            "Score: 0.967048704624176\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "DO: 0.30000000000000004\n",
            "rs: 0.003\n",
            "optimizer: sgd\n",
            "activation: leaky_relu\n",
            "learning_rate: 0.1\n",
            "Score: 0.9614652991294861\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "DO: 0.45000000000000007\n",
            "rs: 0.002\n",
            "optimizer: rmsprop\n",
            "activation: relu\n",
            "learning_rate: 0.001\n",
            "Score: 0.9497367143630981\n",
            "\n",
            "Trial 07 summary\n",
            "Hyperparameters:\n",
            "DO: 0.45000000000000007\n",
            "rs: 0.003\n",
            "optimizer: adam\n",
            "activation: leaky_relu\n",
            "learning_rate: 0.01\n",
            "Score: 0.9305292963981628\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "DO: 0.45000000000000007\n",
            "rs: 0.003\n",
            "optimizer: adam\n",
            "activation: relu\n",
            "learning_rate: 0.0001\n",
            "Score: 0.9272289276123047\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "DO: 0.30000000000000004\n",
            "rs: 0.005\n",
            "optimizer: sgd\n",
            "activation: leaky_relu\n",
            "learning_rate: 0.001\n",
            "Score: 0.9043062329292297\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "DO: 0.35\n",
            "rs: 0.001\n",
            "optimizer: sgd\n",
            "activation: tanh\n",
            "learning_rate: 0.1\n",
            "Score: 0.8168752789497375\n",
            "\n",
            "Trial 05 summary\n",
            "Hyperparameters:\n",
            "DO: 0.5\n",
            "rs: 0.003\n",
            "optimizer: rmsprop\n",
            "activation: tanh\n",
            "learning_rate: 0.01\n",
            "Score: 0.48840126395225525\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "DO: 0.45000000000000007\n",
            "rs: 0.001\n",
            "optimizer: rmsprop\n",
            "activation: tanh\n",
            "learning_rate: 0.1\n",
            "Score: 0.4666064977645874\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 118, 118, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 59, 59, 16)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 59, 59, 16)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 57, 57, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 28, 28, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1605696   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1610849 (6.14 MB)\n",
            "Trainable params: 1610849 (6.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#### función con definicion de hiperparámetros a afinar\n",
        "hp = kt.HyperParameters()\n",
        "def build_model(hp):\n",
        "\n",
        "    dropout_rate=hp.Float('DO', min_value=0.1, max_value= 0.5, step=0.05)\n",
        "    reg_strength = hp.Float(\"rs\", min_value=0.001, max_value=0.005, step=0.001)\n",
        "    optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop']) ### en el contexto no se debería afinar\n",
        "    activation_opt = hp.Choice('activation', ['tanh', 'leaky_relu', 'relu'])  # la función de activación\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01, 0.001, 0.0001])\n",
        "\n",
        "    #filtros1 = hp.Int(\"filtros1\", min_value=16, max_value=128, step=32)\n",
        "    #filtros2 = hp.Int(\"filtros2\", min_value=32, max_value=128, step=32)\n",
        "    #filtros3 = hp.Int(\"filtros3\", min_value=64, max_value=128, step=32)\n",
        "\n",
        "    ####hp.Int\n",
        "    ####hp.Choice\n",
        "\n",
        "\n",
        "    model= tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, kernel_size=(3, 3), activation=activation_opt, input_shape=x_train.shape[1:], kernel_regularizer=tf.keras.regularizers.l2(reg_strength)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=activation_opt, kernel_regularizer=tf.keras.regularizers.l2(reg_strength)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation=activation_opt, kernel_regularizer=tf.keras.regularizers.l2(reg_strength)),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        opt = tf.keras.optimizers.SGD(learning_rate=hp_learning_rate)\n",
        "    else:\n",
        "        opt = tf.keras.optimizers.RMSprop(learning_rate=hp_learning_rate)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=opt, loss=\"binary_crossentropy\",  metrics=[\"Precision\"],\n",
        "    )\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "###########\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    hyperparameters=hp,\n",
        "    tune_new_entries=True,\n",
        "    objective=kt.Objective(\"precision\", direction=\"max\"),\n",
        "    max_trials=10,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"tunnig2\",\n",
        ")\n",
        "\n",
        "\n",
        "tuner.search(x_train_r, y_train_resampled, epochs=5, validation_data=(x_test, y_test), batch_size=100)\n",
        "\n",
        "fc_best_model = tuner.get_best_models(num_models=1)[0]\n",
        "tuner.results_summary()\n",
        "fc_best_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardado de modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnuYnkdRMUYs",
        "outputId": "4dc5b998-dc53-445d-cc71-994c0a3c791c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "fc_best_model.save('/content/salidas/fc_modelres.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modelo con tunning 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utlzwdediCxc",
        "outputId": "c7aebf4f-8b9d-414c-cfde-9a98636af793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 04m 25s]\n",
            "precision: 0.924091100692749\n",
            "\n",
            "Best precision So Far: 0.9565393924713135\n",
            "Total elapsed time: 00h 45m 55s\n",
            "Results summary\n",
            "Results in my_dir/helloworld\n",
            "Showing 10 best trials\n",
            "Objective(name=\"precision\", direction=\"max\")\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "DO: 0.1\n",
            "rs: 0.001\n",
            "optimizer: rmsprop\n",
            "activation: tanh\n",
            "learning_rate: 0.001\n",
            "Score: 0.9565393924713135\n",
            "\n",
            "Trial 05 summary\n",
            "Hyperparameters:\n",
            "DO: 0.35\n",
            "rs: 0.002\n",
            "optimizer: adam\n",
            "activation: leaky_relu\n",
            "learning_rate: 0.001\n",
            "Score: 0.9494787454605103\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "DO: 0.2\n",
            "rs: 0.004\n",
            "optimizer: rmsprop\n",
            "activation: tanh\n",
            "learning_rate: 0.001\n",
            "Score: 0.9388504028320312\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "DO: 0.35\n",
            "rs: 0.002\n",
            "optimizer: sgd\n",
            "activation: relu\n",
            "learning_rate: 0.1\n",
            "Score: 0.924091100692749\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "DO: 0.35\n",
            "rs: 0.003\n",
            "optimizer: sgd\n",
            "activation: relu\n",
            "learning_rate: 0.1\n",
            "Score: 0.8841033577919006\n",
            "\n",
            "Trial 07 summary\n",
            "Hyperparameters:\n",
            "DO: 0.2\n",
            "rs: 0.005\n",
            "optimizer: sgd\n",
            "activation: leaky_relu\n",
            "learning_rate: 0.01\n",
            "Score: 0.85639488697052\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "DO: 0.4\n",
            "rs: 0.004\n",
            "optimizer: sgd\n",
            "activation: leaky_relu\n",
            "learning_rate: 0.01\n",
            "Score: 0.8458877801895142\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "DO: 0.35\n",
            "rs: 0.003\n",
            "optimizer: sgd\n",
            "activation: relu\n",
            "learning_rate: 0.0001\n",
            "Score: 0.6176470518112183\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "DO: 0.5\n",
            "rs: 0.001\n",
            "optimizer: rmsprop\n",
            "activation: tanh\n",
            "learning_rate: 0.01\n",
            "Score: 0.6133210062980652\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "DO: 0.5\n",
            "rs: 0.003\n",
            "optimizer: rmsprop\n",
            "activation: tanh\n",
            "learning_rate: 0.01\n",
            "Score: 0.609684944152832\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 118, 118, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 59, 59, 16)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 59, 59, 16)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 57, 57, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 28, 28, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1605696   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1610849 (6.14 MB)\n",
            "Trainable params: 1610849 (6.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#### función con definicion de hiperparámetros a afinar\n",
        "hp = kt.HyperParameters()\n",
        "def build_model(hp):\n",
        "\n",
        "    dropout_rate=hp.Float('DO', min_value=0.1, max_value= 0.5, step=0.05)\n",
        "    reg_strength = hp.Float(\"rs\", min_value=0.001, max_value=0.005, step=0.001)\n",
        "    optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop']) ### en el contexto no se debería afinar\n",
        "    activation_opt = hp.Choice('activation', ['tanh', 'leaky_relu', 'relu'])  # la función de activación\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01, 0.001, 0.0001])\n",
        "\n",
        "    #filtros1 = hp.Int(\"filtros1\", min_value=16, max_value=128, step=32)\n",
        "    #filtros2 = hp.Int(\"filtros2\", min_value=32, max_value=128, step=32)\n",
        "    #filtros3 = hp.Int(\"filtros3\", min_value=64, max_value=128, step=32)\n",
        "\n",
        "    ####hp.Int\n",
        "    ####hp.Choice\n",
        "\n",
        "\n",
        "    model= tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, kernel_size=(3, 3), activation=activation_opt, input_shape=x_train.shape[1:], kernel_regularizer=tf.keras.regularizers.l2(reg_strength)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=activation_opt, kernel_regularizer=tf.keras.regularizers.l2(reg_strength)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation=activation_opt, kernel_regularizer=tf.keras.regularizers.l2(reg_strength)),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        opt = tf.keras.optimizers.SGD(learning_rate=hp_learning_rate)\n",
        "    else:\n",
        "        opt = tf.keras.optimizers.RMSprop(learning_rate=hp_learning_rate)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=opt, loss=\"binary_crossentropy\",  metrics=[\"Recall\", \"Precision\", \"Accuracy\"],\n",
        "    )\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "###########\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    hyperparameters=hp,\n",
        "    tune_new_entries=True,\n",
        "    objective=kt.Objective(\"precision\", direction=\"max\"),\n",
        "    max_trials=10,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"helloworld\",\n",
        ")\n",
        "\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test), batch_size=100)\n",
        "\n",
        "fc_best_model = tuner.get_best_models(num_models=1)[0]\n",
        "tuner.results_summary()\n",
        "fc_best_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardado de modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUb3lkx-iFjx",
        "outputId": "0c5bceb8-e49d-44be-8b4f-72286daeda73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "fc_best_model.save('/content/salidas/fc_model4.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
